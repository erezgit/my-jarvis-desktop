import { toFilter } from "./filter.js";
import { compareLogLevel } from "./level.js";
import { defaultConsoleFormatter, defaultTextFormatter } from "./formatter.js";

//#region src/sink.ts
/**
* Turns a sink into a filtered sink.  The returned sink only logs records that
* pass the filter.
*
* @example Filter a console sink to only log records with the info level
* ```typescript
* const sink = withFilter(getConsoleSink(), "info");
* ```
*
* @param sink A sink to be filtered.
* @param filter A filter to apply to the sink.  It can be either a filter
*               function or a {@link LogLevel} string.
* @returns A sink that only logs records that pass the filter.
*/
function withFilter(sink, filter) {
	const filterFunc = toFilter(filter);
	return (record) => {
		if (filterFunc(record)) sink(record);
	};
}
/**
* A factory that returns a sink that writes to a {@link WritableStream}.
*
* Note that the `stream` is of Web Streams API, which is different from
* Node.js streams.  You can convert a Node.js stream to a Web Streams API
* stream using [`stream.Writable.toWeb()`] method.
*
* [`stream.Writable.toWeb()`]: https://nodejs.org/api/stream.html#streamwritabletowebstreamwritable
*
* @example Sink to the standard error in Deno
* ```typescript
* const stderrSink = getStreamSink(Deno.stderr.writable);
* ```
*
* @example Sink to the standard error in Node.js
* ```typescript
* import stream from "node:stream";
* const stderrSink = getStreamSink(stream.Writable.toWeb(process.stderr));
* ```
*
* @param stream The stream to write to.
* @param options The options for the sink.
* @returns A sink that writes to the stream.
*/
function getStreamSink(stream, options = {}) {
	const formatter = options.formatter ?? defaultTextFormatter;
	const encoder = options.encoder ?? new TextEncoder();
	const writer = stream.getWriter();
	if (!options.nonBlocking) {
		let lastPromise = Promise.resolve();
		const sink = (record) => {
			const bytes = encoder.encode(formatter(record));
			lastPromise = lastPromise.then(() => writer.ready).then(() => writer.write(bytes));
		};
		sink[Symbol.asyncDispose] = async () => {
			await lastPromise;
			await writer.close();
		};
		return sink;
	}
	const nonBlockingConfig = options.nonBlocking === true ? {} : options.nonBlocking;
	const bufferSize = nonBlockingConfig.bufferSize ?? 100;
	const flushInterval = nonBlockingConfig.flushInterval ?? 100;
	const buffer = [];
	let flushTimer = null;
	let disposed = false;
	let activeFlush = null;
	const maxBufferSize = bufferSize * 2;
	async function flush() {
		if (buffer.length === 0) return;
		const records = buffer.splice(0);
		for (const record of records) try {
			const bytes = encoder.encode(formatter(record));
			await writer.ready;
			await writer.write(bytes);
		} catch {}
	}
	function scheduleFlush() {
		if (activeFlush) return;
		activeFlush = flush().finally(() => {
			activeFlush = null;
		});
	}
	function startFlushTimer() {
		if (flushTimer !== null || disposed) return;
		flushTimer = setInterval(() => {
			scheduleFlush();
		}, flushInterval);
	}
	const nonBlockingSink = (record) => {
		if (disposed) return;
		if (buffer.length >= maxBufferSize) buffer.shift();
		buffer.push(record);
		if (buffer.length >= bufferSize) scheduleFlush();
		else if (flushTimer === null) startFlushTimer();
	};
	nonBlockingSink[Symbol.asyncDispose] = async () => {
		disposed = true;
		if (flushTimer !== null) {
			clearInterval(flushTimer);
			flushTimer = null;
		}
		await flush();
		try {
			await writer.close();
		} catch {}
	};
	return nonBlockingSink;
}
/**
* A console sink factory that returns a sink that logs to the console.
*
* @param options The options for the sink.
* @returns A sink that logs to the console. If `nonBlocking` is enabled,
*          returns a sink that also implements {@link Disposable}.
*/
function getConsoleSink(options = {}) {
	const formatter = options.formatter ?? defaultConsoleFormatter;
	const levelMap = {
		trace: "debug",
		debug: "debug",
		info: "info",
		warning: "warn",
		error: "error",
		fatal: "error",
		...options.levelMap ?? {}
	};
	const console = options.console ?? globalThis.console;
	const baseSink = (record) => {
		const args = formatter(record);
		const method = levelMap[record.level];
		if (method === void 0) throw new TypeError(`Invalid log level: ${record.level}.`);
		if (typeof args === "string") {
			const msg = args.replace(/\r?\n$/, "");
			console[method](msg);
		} else console[method](...args);
	};
	if (!options.nonBlocking) return baseSink;
	const nonBlockingConfig = options.nonBlocking === true ? {} : options.nonBlocking;
	const bufferSize = nonBlockingConfig.bufferSize ?? 100;
	const flushInterval = nonBlockingConfig.flushInterval ?? 100;
	const buffer = [];
	let flushTimer = null;
	let disposed = false;
	let flushScheduled = false;
	const maxBufferSize = bufferSize * 2;
	function flush() {
		if (buffer.length === 0) return;
		const records = buffer.splice(0);
		for (const record of records) try {
			baseSink(record);
		} catch {}
	}
	function scheduleFlush() {
		if (flushScheduled) return;
		flushScheduled = true;
		setTimeout(() => {
			flushScheduled = false;
			flush();
		}, 0);
	}
	function startFlushTimer() {
		if (flushTimer !== null || disposed) return;
		flushTimer = setInterval(() => {
			flush();
		}, flushInterval);
	}
	const nonBlockingSink = (record) => {
		if (disposed) return;
		if (buffer.length >= maxBufferSize) buffer.shift();
		buffer.push(record);
		if (buffer.length >= bufferSize) scheduleFlush();
		else if (flushTimer === null) startFlushTimer();
	};
	nonBlockingSink[Symbol.dispose] = () => {
		disposed = true;
		if (flushTimer !== null) {
			clearInterval(flushTimer);
			flushTimer = null;
		}
		flush();
	};
	return nonBlockingSink;
}
/**
* Converts an async sink into a regular sink with proper async handling.
* The returned sink chains async operations to ensure proper ordering and
* implements AsyncDisposable to wait for all pending operations on disposal.
*
* @example Create a sink that asynchronously posts to a webhook
* ```typescript
* const asyncSink: AsyncSink = async (record) => {
*   await fetch("https://example.com/logs", {
*     method: "POST",
*     body: JSON.stringify(record),
*   });
* };
* const sink = fromAsyncSink(asyncSink);
* ```
*
* @param asyncSink The async sink function to convert.
* @returns A sink that properly handles async operations and disposal.
* @since 1.0.0
*/
function fromAsyncSink(asyncSink) {
	let lastPromise = Promise.resolve();
	const sink = (record) => {
		lastPromise = lastPromise.then(() => asyncSink(record)).catch(() => {});
	};
	sink[Symbol.asyncDispose] = async () => {
		await lastPromise;
	};
	return sink;
}
/**
* Creates a sink that buffers log records until a trigger level is reached.
* This pattern, known as "fingers crossed" logging, keeps detailed debug logs
* in memory and only outputs them when an error or other significant event occurs.
*
* @example Basic usage with default settings
* ```typescript
* const sink = fingersCrossed(getConsoleSink());
* // Debug and info logs are buffered
* // When an error occurs, all buffered logs + the error are output
* ```
*
* @example Custom trigger level and buffer size
* ```typescript
* const sink = fingersCrossed(getConsoleSink(), {
*   triggerLevel: "warning",  // Trigger on warning or higher
*   maxBufferSize: 500        // Keep last 500 records
* });
* ```
*
* @example Category isolation
* ```typescript
* const sink = fingersCrossed(getConsoleSink(), {
*   isolateByCategory: "descendant"  // Separate buffers per category
* });
* // Error in ["app"] triggers flush of ["app"] and ["app", "module"] buffers
* // But not ["other"] buffer
* ```
*
* @param sink The sink to wrap. Buffered records are sent to this sink when
*             triggered.
* @param options Configuration options for the fingers crossed behavior.
* @returns A sink that buffers records until the trigger level is reached.
* @since 1.1.0
*/
function fingersCrossed(sink, options = {}) {
	const triggerLevel = options.triggerLevel ?? "error";
	const maxBufferSize = Math.max(0, options.maxBufferSize ?? 1e3);
	const isolateByCategory = options.isolateByCategory;
	try {
		compareLogLevel("trace", triggerLevel);
	} catch (error) {
		throw new TypeError(`Invalid triggerLevel: ${JSON.stringify(triggerLevel)}. ${error instanceof Error ? error.message : String(error)}`);
	}
	function isDescendant(parent, child) {
		if (parent.length === 0 || child.length === 0) return false;
		if (parent.length > child.length) return false;
		return parent.every((p, i) => p === child[i]);
	}
	function isAncestor(child, parent) {
		if (child.length === 0 || parent.length === 0) return false;
		if (child.length < parent.length) return false;
		return parent.every((p, i) => p === child[i]);
	}
	let shouldFlushBuffer = null;
	if (isolateByCategory) if (typeof isolateByCategory === "function") shouldFlushBuffer = isolateByCategory;
	else switch (isolateByCategory) {
		case "descendant":
			shouldFlushBuffer = (trigger, buffered) => isDescendant(trigger, buffered);
			break;
		case "ancestor":
			shouldFlushBuffer = (trigger, buffered) => isAncestor(trigger, buffered);
			break;
		case "both":
			shouldFlushBuffer = (trigger, buffered) => isDescendant(trigger, buffered) || isAncestor(trigger, buffered);
			break;
	}
	function getCategoryKey(category) {
		return JSON.stringify(category);
	}
	function parseCategoryKey(key) {
		return JSON.parse(key);
	}
	if (!isolateByCategory) {
		const buffer = [];
		let triggered = false;
		return (record) => {
			if (triggered) {
				sink(record);
				return;
			}
			if (compareLogLevel(record.level, triggerLevel) >= 0) {
				triggered = true;
				for (const bufferedRecord of buffer) sink(bufferedRecord);
				buffer.length = 0;
				sink(record);
			} else {
				buffer.push(record);
				while (buffer.length > maxBufferSize) buffer.shift();
			}
		};
	} else {
		const buffers = /* @__PURE__ */ new Map();
		const triggered = /* @__PURE__ */ new Set();
		return (record) => {
			const categoryKey = getCategoryKey(record.category);
			if (triggered.has(categoryKey)) {
				sink(record);
				return;
			}
			if (compareLogLevel(record.level, triggerLevel) >= 0) {
				const keysToFlush = /* @__PURE__ */ new Set();
				for (const [bufferedKey] of buffers) if (bufferedKey === categoryKey) keysToFlush.add(bufferedKey);
				else if (shouldFlushBuffer) {
					const bufferedCategory = parseCategoryKey(bufferedKey);
					try {
						if (shouldFlushBuffer(record.category, bufferedCategory)) keysToFlush.add(bufferedKey);
					} catch {}
				}
				const allRecordsToFlush = [];
				for (const key of keysToFlush) {
					const buffer = buffers.get(key);
					if (buffer) {
						allRecordsToFlush.push(...buffer);
						buffers.delete(key);
						triggered.add(key);
					}
				}
				allRecordsToFlush.sort((a, b) => a.timestamp - b.timestamp);
				for (const bufferedRecord of allRecordsToFlush) sink(bufferedRecord);
				triggered.add(categoryKey);
				sink(record);
			} else {
				let buffer = buffers.get(categoryKey);
				if (!buffer) {
					buffer = [];
					buffers.set(categoryKey, buffer);
				}
				buffer.push(record);
				while (buffer.length > maxBufferSize) buffer.shift();
			}
		};
	}
}

//#endregion
export { fingersCrossed, fromAsyncSink, getConsoleSink, getStreamSink, withFilter };
//# sourceMappingURL=sink.js.map